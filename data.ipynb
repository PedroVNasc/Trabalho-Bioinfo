{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import json\n",
    "import dill\n",
    "import wget\n",
    "from scipy.fftpack import fft\n",
    "from Bio import Entrez\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente é feita a filtragem dos Dados iniciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./data/raw', exist_ok=True)\n",
    "\n",
    "classes = ['LTR', 'LINE', 'SINE', 'TIR', 'MITE', 'Helitron']\n",
    "\n",
    "file_paths = os.listdir('./data/raw')\n",
    "print(file_paths)\n",
    "\n",
    "for name in classes:\n",
    "    if f'TEAnnotationFinal_{name}.gff3' not in file_paths:\n",
    "        wget.download(f'http://apte.cp.utfpr.edu.br/te-annotation/zea_mays/TEAnnotationFinal_{name}.gff3',\n",
    "                      out=f'./data/raw/')\n",
    "\n",
    "file_paths = os.listdir('./data/raw')\n",
    "\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame()\n",
    "\n",
    "if not os.path.isfile('./data/classes.csv'):\n",
    "    data = []\n",
    "\n",
    "    for path in file_paths:\n",
    "        with open(f'./data/raw/{path}', 'r') as f:\n",
    "            reader = csv.reader(f, delimiter='\\t')\n",
    "\n",
    "            class_name = path.split('.')[0].split('_')[1]\n",
    "\n",
    "            for row in reader:\n",
    "                if (row[6] == '+'):\n",
    "                    data.append([class_name] + row)\n",
    "\n",
    "    header = ['Class', 'Chr', 'Source Annotation', 'Class/Order/Superfamily', 'Start', 'End', 'Score', 'Strand', 'Phase', 'Attributes']\n",
    "\n",
    "    data_df = pd.DataFrame(data, columns=header)\n",
    "    data_df = data_df[['Class', 'Chr', 'Start', 'End']]\n",
    "\n",
    "    data_df.to_csv('./data/classes.csv')\n",
    "\n",
    "else:\n",
    "    data_df = pd.read_csv('./data/classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Start'] = data_df['Start'].astype('int64')\n",
    "data_df['End'] = data_df['End'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em sequência será feita a extração dos genomas por meio de Biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dict = {\"LR618874.1\": \"Chr_1.txt\", \"LR618875.1\": \"Chr_2.txt\", \"LR618876.1\": \"Chr_3.txt\", \"LR618877.1\": \"Chr_4.txt\", \n",
    "           \"LR618878.1\": \"Chr_5.txt\", \"LR618879.1\": \"Chr_6.txt\", \"LR618880.1\": \"Chr_7.txt\", \"LR618881.1\": \"Chr_8.txt\", \n",
    "           \"LR618882.1\": \"Chr_9.txt\", \"LR618883.1\": \"Chr_10.txt\", \"AY506529.1\":\"Chr_Mt.txt\", \"X86563.2\": \"Chr_Pt.txt\"}\n",
    "\n",
    "Entrez.email = \"pedro.guilherme2305@usp.br\"\n",
    "\n",
    "os.makedirs('./data/sequences', exist_ok=True)\n",
    "\n",
    "for id in tqdm(id_dict, total=len(id_dict)):\n",
    "    if not os.path.isfile(f'./data/sequences/{id_dict[id]}'):\n",
    "        stream = Entrez.efetch(db=\"nuccore\", id=id, rettype=\"fasta\")\n",
    "\n",
    "        with open(f\"./data/sequences/{id_dict[id]}\", \"w\") as file:\n",
    "            file.write(stream.read())\n",
    "        stream.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(data_df: pd.DataFrame):\n",
    "    chromosomes_to_keep = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'Mt', 'Pt']\n",
    "    data_df = data_df.query(\"Chr in @chromosomes_to_keep\") \n",
    "\n",
    "    aux_list = []\n",
    "\n",
    "    for chromosome in chromosomes_to_keep:\n",
    "        rows = data_df.query(f\"Chr == '{chromosome}'\").to_dict(orient=\"records\")\n",
    "        record = SeqIO.read(f\"./data/sequences/Chr_{chromosome}.txt\", \"fasta\")\n",
    "        for row in tqdm(rows, total=len(rows)):\n",
    "            aux_dict = dict()\n",
    "\n",
    "            aux_dict['Chr'] = row['Chr']\n",
    "            aux_dict['Sequence'] = record[row['Start']:row['End']].seq\n",
    "            aux_dict['Class'] = row['Class']\n",
    "\n",
    "            if aux_dict['Sequence'] == '': aux_dict['Sequence'] = np.nan\n",
    "\n",
    "            aux_list.append(aux_dict)\n",
    "    \n",
    "    return aux_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feauture Extraction - Accumulated Nucle Frequency Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(spectrum, spectrumTwo):\n",
    "    features = []\n",
    "\n",
    "    average = sum(spectrum)/len(spectrum)\n",
    "    features.append(average)\n",
    "    ###################################\n",
    "    median = np.median(spectrum)\n",
    "    features.append(median)\n",
    "\t###################################\n",
    "    maximum = np.max(spectrum)\n",
    "    features.append(maximum)\n",
    "    ###################################\n",
    "    minimum = np.min(spectrum)\n",
    "    features.append(minimum)\n",
    "    ###################################\n",
    "    peak = (len(spectrum)/3)/(average)\n",
    "    features.append(peak)\n",
    "    ###################################\n",
    "    peak_two = (len(spectrumTwo)/3)/(np.mean(spectrumTwo))\n",
    "    features.append(peak_two)\n",
    "    ###################################\n",
    "    standard_deviation = np.std(spectrum) # standard deviation\n",
    "    features.append(standard_deviation)\n",
    "    ###################################\n",
    "    standard_deviation_pop = statistics.stdev(spectrum) # population sample standard deviation \n",
    "    features.append(standard_deviation_pop)\n",
    "    ###################################\n",
    "    percentile15 = np.percentile(spectrum, 15)\n",
    "    features.append(percentile15)\n",
    "    ###################################\n",
    "    percentile25 = np.percentile(spectrum, 25)\n",
    "    features.append(percentile25)\n",
    "    ###################################\n",
    "    percentile50 = np.percentile(spectrum, 50)\n",
    "    features.append(percentile50)\n",
    "    ###################################\n",
    "    percentile75 = np.percentile(spectrum, 75)\n",
    "    features.append(percentile75)\n",
    "    ###################################\n",
    "    amplitude = maximum - minimum\n",
    "    features.append(amplitude)\n",
    "    ###################################\n",
    "    # mode = statistics.mode(spectrum)\n",
    "    ###################################\n",
    "    variance = statistics.variance(spectrum)\n",
    "    features.append(variance)\n",
    "    ###################################\n",
    "    interquartile_range = np.percentile(spectrum, 75) - np.percentile(spectrum, 25)\n",
    "    features.append(interquartile_range)\n",
    "    ###################################\n",
    "    semi_interquartile_range = (np.percentile(spectrum, 75) - np.percentile(spectrum, 25))/2 \n",
    "    features.append(semi_interquartile_range)\n",
    "    ###################################\n",
    "    coefficient_of_variation = standard_deviation/average\n",
    "    features.append(coefficient_of_variation)\n",
    "    ###################################\n",
    "    skewness = (3 * (average - median))/standard_deviation\n",
    "    features.append(skewness)   \n",
    "    ###################################\n",
    "    kurtosis = (np.percentile(spectrum, 75) - np.percentile(spectrum, 25)) / (2 * (np.percentile(spectrum, 90) - np.percentile(spectrum, 10))) \n",
    "    features.append(kurtosis)\n",
    "    ###################################\n",
    "    return features\n",
    "\n",
    "\n",
    "def accumulated_nucle_frequency_fourier(seq):\n",
    "    \n",
    "    seq = seq.upper()\n",
    "    features = []\n",
    "    spectrum = []\n",
    "    spectrumTwo = []\n",
    "    mapping = []\n",
    "    A = 0\n",
    "    C = 0\n",
    "    T = 0\n",
    "    G = 0\n",
    "    for i in range(len(seq)):\n",
    "        if seq[i] == 'A':\n",
    "            A += 1\n",
    "            mapping.append(A / (i + 1))\n",
    "        elif seq[i] == 'C':\n",
    "            C += 1\n",
    "            mapping.append(C / (i + 1))\n",
    "        elif seq[i] == 'T' or seq[i] == 'U':\n",
    "            T += 1\n",
    "            mapping.append(T / (i + 1))\n",
    "        else:\n",
    "            G += 1\n",
    "            mapping.append(G / (i + 1))\n",
    "    Fmap = fft(mapping)\n",
    "    for i in range(len(mapping)):\n",
    "        specTotal = (abs(Fmap[i])**2)\n",
    "        specTwo = (abs(Fmap[i]))\n",
    "        spectrum.append(specTotal)\n",
    "        spectrumTwo.append(specTwo)\n",
    "    \n",
    "    features = feature_extraction(spectrum, spectrumTwo)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(final_df: pd.DataFrame, columns: list):\n",
    "    features_dict = {}\n",
    "\n",
    "    if not os.path.isfile('./data/features.json'):\n",
    "        sequence_list = final_df['Sequence'].to_list()\n",
    "\n",
    "        features_list = []\n",
    "        for seq in tqdm(sequence_list, total=len(sequence_list)):\n",
    "            features_list.append(accumulated_nucle_frequency_fourier(seq))\n",
    "\n",
    "        features_list = np.array(features_list)\n",
    " \n",
    "        features_dict = {}\n",
    "        for i in tqdm(range(len(columns))):\n",
    "            features_dict[columns[i]] = list(features_list[:, i])\n",
    "\n",
    "        with open('./data/features.json', 'w') as f: \n",
    "            json.dump(features_dict, f)\n",
    "\n",
    "    else:\n",
    "        with open('./data/features.json', 'r') as f: \n",
    "            features_dict = json.load(f)\n",
    "    \n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1173/3046178905.py:23: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_df = pd.read_csv('./data/final.csv')\n"
     ]
    }
   ],
   "source": [
    "columns = ['average', 'median', 'maximum', 'minimum', 'peak', 'none_levated_peak', 'sample_standard_deviation', 'population_standard_deviation', \\\n",
    "        'percentile15', 'percentile25', 'percentile50', 'percentile75', 'amplitude', 'variance', 'interquartile_range', 'semi_interquartile_range', \\\n",
    "        'coefficient_of_variation', 'skewness', 'kurtosis']\n",
    "\n",
    "if not os.path.isfile('./data/final.csv'):\n",
    "    aux_list = generate_sequences(data_df)\n",
    "\n",
    "    final_df = pd.DataFrame(aux_list)\n",
    "    final_df = final_df.dropna()\n",
    "    final_df.head()\n",
    "\n",
    "    features_dict = generate_features(final_df, columns)\n",
    "\n",
    "    for column in columns:\n",
    "        final_df[column] = features_dict[column]\n",
    "\n",
    "    final_df = final_df.dropna()\n",
    "    final_df.head()\n",
    "\n",
    "    final_df.to_csv('./data/final.csv')\n",
    "\n",
    "else:\n",
    "    final_df = pd.read_csv('./data/final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[[column for column in final_df.columns if column != 'Unnamed: 0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "Helitron     24513\n",
       "LINE         11058\n",
       "LTR         189795\n",
       "MITE         26094\n",
       "SINE          3697\n",
       "TIR          83113\n",
       "Name: Chr, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.groupby('Class')['Chr'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = final_df['Class'].to_list()\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(class_list)\n",
    "\n",
    "columns = ['average', 'median', 'maximum', 'minimum', 'peak', 'none_levated_peak', 'sample_standard_deviation', 'population_standard_deviation', \\\n",
    "            'percentile15', 'percentile25', 'percentile50', 'percentile75', 'amplitude', 'variance', 'interquartile_range', 'semi_interquartile_range', \\\n",
    "            'coefficient_of_variation', 'skewness', 'kurtosis']\n",
    "\n",
    "x = final_df[columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_resample, y_resample = NearMiss(sampling_strategy={0:15000, 2:15000, 3:15000, 5:15000}).fit_resample(x, y)\n",
    "x_resample, y_resample = SMOTE(sampling_strategy={1: 15000, 4:15000}).fit_resample(x_resample, y_resample)\n",
    "y_resample = label_binarize(y_resample, classes=[0, 1, 2, 3, 4, 5])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_resample, y_resample, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = make_pipeline(StandardScaler(), OneVsRestClassifier(RandomForestClassifier(criterion='gini', n_estimators=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list = []\n",
    "criterion_list = ['gini', 'log_loss']\n",
    "tree_num_list = [50, 100, 200]\n",
    "for tree_num in tree_num_list:\n",
    "    for criterion in criterion_list:\n",
    "        classifier = make_pipeline(StandardScaler(), OneVsRestClassifier(RandomForestClassifier(criterion=criterion, n_estimators=tree_num)))\n",
    "        classifier_list.append({'criterion':criterion, 'tree_num': tree_num, 'classifier': classifier})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "path = './data/classifiers/'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "for classifier in tqdm(classifier_list, total=len(classifier_list)):\n",
    "    \n",
    "    file_name = f'classifier_{classifier['criterion']}_{classifier['tree_num']}.pkl'\n",
    "\n",
    "    if file_name in list(os.listdir('./data/classifiers/')):\n",
    "        with open(f'{path}/{file_name}', 'rb') as f: classifier['classifier'] = dill.load(f)\n",
    "    else:\n",
    "        classifier['classifier'].fit(x_train, y_train)\n",
    "        with open(f'{path}/{file_name}', 'wb') as f: dill.dump(classifier['classifier'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paoebom/micromamba/envs/bioinfo/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Helitron       0.93      0.80      0.86      4489\n",
      "        LINE       0.91      0.72      0.81      4504\n",
      "         LTR       0.98      0.73      0.83      4430\n",
      "        MITE       0.90      0.76      0.83      4521\n",
      "        SINE       0.93      0.56      0.70      4520\n",
      "         TIR       0.94      0.75      0.83      4536\n",
      "\n",
      "   micro avg       0.93      0.72      0.81     27000\n",
      "   macro avg       0.93      0.72      0.81     27000\n",
      "weighted avg       0.93      0.72      0.81     27000\n",
      " samples avg       0.72      0.72      0.72     27000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paoebom/micromamba/envs/bioinfo/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Helitron       0.93      0.80      0.86      4489\n",
      "        LINE       0.92      0.72      0.81      4504\n",
      "         LTR       0.98      0.73      0.83      4430\n",
      "        MITE       0.91      0.76      0.83      4521\n",
      "        SINE       0.93      0.57      0.70      4520\n",
      "         TIR       0.94      0.74      0.83      4536\n",
      "\n",
      "   micro avg       0.93      0.72      0.81     27000\n",
      "   macro avg       0.94      0.72      0.81     27000\n",
      "weighted avg       0.94      0.72      0.81     27000\n",
      " samples avg       0.72      0.72      0.72     27000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paoebom/micromamba/envs/bioinfo/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Helitron       0.93      0.79      0.85      4489\n",
      "        LINE       0.92      0.72      0.81      4504\n",
      "         LTR       0.97      0.73      0.83      4430\n",
      "        MITE       0.91      0.75      0.82      4521\n",
      "        SINE       0.95      0.58      0.72      4520\n",
      "         TIR       0.93      0.73      0.82      4536\n",
      "\n",
      "   micro avg       0.93      0.72      0.81     27000\n",
      "   macro avg       0.93      0.72      0.81     27000\n",
      "weighted avg       0.93      0.72      0.81     27000\n",
      " samples avg       0.72      0.72      0.72     27000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Helitron       0.93      0.79      0.85      4489\n",
      "        LINE       0.92      0.72      0.81      4504\n",
      "         LTR       0.98      0.73      0.83      4430\n",
      "        MITE       0.91      0.75      0.82      4521\n",
      "        SINE       0.95      0.59      0.73      4520\n",
      "         TIR       0.93      0.73      0.82      4536\n",
      "\n",
      "   micro avg       0.93      0.72      0.81     27000\n",
      "   macro avg       0.94      0.72      0.81     27000\n",
      "weighted avg       0.94      0.72      0.81     27000\n",
      " samples avg       0.72      0.72      0.72     27000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paoebom/micromamba/envs/bioinfo/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifier_list:\n",
    "    y_pred = classifier['classifier'].predict(x_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=['Helitron', 'LINE', 'LTR', 'MITE', 'SINE', 'TIR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Helitron       0.69      0.30      0.41      4450\n",
      "        LINE       0.69      0.40      0.51      4566\n",
      "         LTR       0.61      0.11      0.18      4449\n",
      "        MITE       0.57      0.23      0.33      4561\n",
      "        SINE       0.81      0.48      0.60      4466\n",
      "         TIR       0.55      0.18      0.27      4508\n",
      "\n",
      "   micro avg       0.68      0.28      0.40     27000\n",
      "   macro avg       0.65      0.28      0.39     27000\n",
      "weighted avg       0.65      0.28      0.39     27000\n",
      " samples avg       0.28      0.28      0.28     27000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paoebom/micromamba/envs/bioinfo/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['Helitron', 'LINE', 'LTR', 'MITE', 'SINE', 'TIR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27585185185185185\n",
      "Precision: 0.6532132781253848\n",
      "Recall: 0.28125925925925926\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/classifier.pkl', 'wb') as f: dill.dump(classifier, f) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
